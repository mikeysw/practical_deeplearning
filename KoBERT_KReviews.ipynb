{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o1ERA1mVTdgS",
        "outputId": "03789a2d-f1e4-4841-bb2e-f76a47a896c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://****@github.com/SKTBrain/KoBERT.git@master\n",
            "  Cloning https://****@github.com/SKTBrain/KoBERT.git (to revision master) to /tmp/pip-req-build-xaud3_ux\n",
            "  Running command git clone --filter=blob:none --quiet 'https://****@github.com/SKTBrain/KoBERT.git' /tmp/pip-req-build-xaud3_ux\n",
            "  Resolved https://****@github.com/SKTBrain/KoBERT.git to commit 47a69af87928fc24e20f571fe10c3cc9dd9af9a3\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting boto3<=1.15.18 (from kobert==0.2.3)\n",
            "  Using cached boto3-1.15.18-py2.py3-none-any.whl (129 kB)\n",
            "Collecting gluonnlp<=0.10.0,>=0.6.0 (from kobert==0.2.3)\n",
            "  Using cached gluonnlp-0.10.0.tar.gz (344 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting mxnet<=1.7.0.post2,>=1.4.0 (from kobert==0.2.3)\n",
            "  Using cached mxnet-1.7.0.post2-py2.py3-none-manylinux2014_x86_64.whl (54.7 MB)\n",
            "INFO: pip is looking at multiple versions of kobert to determine which version is compatible with other requirements. This could take a while.\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement onnxruntime<=1.8.0,==1.8.0 (from kobert) (from versions: 1.12.0, 1.12.1, 1.13.1, 1.14.0, 1.14.1, 1.15.0, 1.15.1, 1.16.0, 1.16.1, 1.16.2, 1.16.3, 1.17.0, 1.17.1, 1.17.3, 1.18.0)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for onnxruntime<=1.8.0,==1.8.0\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.0+cu121)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.41.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.0.3)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.1.99)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.5.40)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.6.2)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://git@github.com/SKTBrain/KoBERT.git@master\n",
        "!pip install torch transformers pandas sentencepiece"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZcVMBWw_Tk1m",
        "outputId": "20e0f4e1-5e86-4e8b-c938-d5a5cca30e46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pathtrain = '/content/drive/MyDrive/combined_data_new_train.json'\n",
        "pathtest = '/content/drive/MyDrive/combined_data_new_val.json'"
      ],
      "metadata": {
        "id": "Id4mhMMDTlVu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pathtrain2 = '/content/drive/MyDrive/combined_data_final_train.json'\n",
        "pathtest2 = '/content/drive/MyDrive/combined_data_final_test.json'"
      ],
      "metadata": {
        "id": "gC4HN4UfuBeI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset, random_split\n",
        "from transformers import BertTokenizer, BertModel\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import accuracy_score, mean_absolute_error"
      ],
      "metadata": {
        "id": "yeaGp7knYFzL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ReviewDataset(Dataset):\n",
        "    def __init__(self, data_path, tokenizer, max_length):\n",
        "        self.data = []\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "        with open(data_path, 'r', encoding='utf-8') as f:\n",
        "            raw_data = json.load(f)\n",
        "            for item in raw_data:\n",
        "                if item[\"GeneralPolarity\"] is not None and item[\"ReviewScore\"] is not None:\n",
        "                    self.data.append(item)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = self.data[idx]\n",
        "        inputs = self.tokenizer(\n",
        "            item[\"RawText\"],\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            max_length=self.max_length,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        input_ids = inputs[\"input_ids\"].squeeze(0)\n",
        "        attention_mask = inputs[\"attention_mask\"].squeeze(0)\n",
        "\n",
        "        review_score = torch.tensor(float(item[\"ReviewScore\"]) / 100.0, dtype=torch.float32)\n",
        "        general_polarity = torch.tensor(int(item[\"GeneralPolarity\"]) + 1, dtype=torch.long)\n",
        "\n",
        "        return input_ids, attention_mask, review_score, general_polarity"
      ],
      "metadata": {
        "id": "BYUtFPJTYH6-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiTaskModel(nn.Module):\n",
        "    def __init__(self, bert_model_name, num_polarity_classes=3):\n",
        "        super(MultiTaskModel, self).__init__()\n",
        "        self.bert = BertModel.from_pretrained(bert_model_name)\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.classifier = nn.Linear(self.bert.config.hidden_size, num_polarity_classes)\n",
        "        self.regressor = nn.Linear(self.bert.config.hidden_size, 1)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        pooled_output = outputs[1]\n",
        "        pooled_output = self.dropout(pooled_output)\n",
        "\n",
        "        polarity_logits = self.classifier(pooled_output)\n",
        "        review_score = self.regressor(pooled_output).squeeze(-1)\n",
        "\n",
        "        return polarity_logits, review_score"
      ],
      "metadata": {
        "id": "5YCyrbcbYIij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, dataloader, optimizer, criterion_classification, criterion_regression, device):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for batch in tqdm(dataloader):\n",
        "        input_ids, attention_mask, review_score, general_polarity = [x.to(device) for x in batch]\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        polarity_logits, predicted_score = model(input_ids, attention_mask)\n",
        "\n",
        "        loss_classification = criterion_classification(polarity_logits, general_polarity)\n",
        "        loss_regression = criterion_regression(predicted_score, review_score)\n",
        "\n",
        "        loss = loss_classification + loss_regression\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(dataloader)"
      ],
      "metadata": {
        "id": "8HL94G-JYKGK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, dataloader, criterion_classification, criterion_regression, device):\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    all_predictions = []\n",
        "    all_scores = []\n",
        "    all_labels = []\n",
        "    all_review_scores = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(dataloader):\n",
        "            input_ids, attention_mask, review_score, general_polarity = [x.to(device) for x in batch]\n",
        "\n",
        "            polarity_logits, predicted_score = model(input_ids, attention_mask)\n",
        "\n",
        "            loss_classification = criterion_classification(polarity_logits, general_polarity)\n",
        "            loss_regression = criterion_regression(predicted_score, review_score)\n",
        "\n",
        "            loss = loss_classification + loss_regression\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            all_predictions.extend(polarity_logits.argmax(dim=1).cpu().numpy())\n",
        "            all_scores.extend(predicted_score.cpu().numpy())\n",
        "            all_labels.extend(general_polarity.cpu().numpy())\n",
        "            all_review_scores.extend(review_score.cpu().numpy())\n",
        "\n",
        "    return total_loss / len(dataloader), all_predictions, all_scores, all_labels, all_review_scores\n",
        "\n",
        "def calculate_metrics(predictions, scores, labels, review_scores):\n",
        "    # 감성 분석 정확도\n",
        "    accuracy = accuracy_score(labels, predictions)\n",
        "    # 별점 예측 MAE\n",
        "    mae = mean_absolute_error([score * 100 for score in review_scores], [score * 100 for score in scores])\n",
        "    return accuracy, mae"
      ],
      "metadata": {
        "id": "M01LXlSYYL1c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Device 설정\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# 모델 및 토크나이저 로드\n",
        "model = MultiTaskModel('monologg/kobert').to(device)\n",
        "tokenizer = BertTokenizer.from_pretrained('monologg/kobert')\n",
        "\n",
        "# Train 데이터셋 로드 및 분할\n",
        "train_dataset = ReviewDataset(pathtrain2, tokenizer, max_length=128)\n",
        "train_size = int(0.8 * len(train_dataset))\n",
        "val_size = len(train_dataset) - train_size\n",
        "train_subset, val_subset = random_split(train_dataset, [train_size, val_size])\n",
        "\n",
        "train_dataloader = DataLoader(train_subset, batch_size=32, shuffle=True)\n",
        "val_dataloader = DataLoader(val_subset, batch_size=32, shuffle=False)\n",
        "\n",
        "# Validation 데이터셋을 Test 데이터셋으로 사용\n",
        "test_dataset = ReviewDataset(pathtest2, tokenizer, max_length=128)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# 손실 함수 정의\n",
        "criterion_classification = nn.CrossEntropyLoss()\n",
        "criterion_regression = nn.MSELoss()\n",
        "\n",
        "# Optimizer 설정\n",
        "optimizer = optim.AdamW(model.parameters(), lr=3e-5)"
      ],
      "metadata": {
        "id": "01DxwvtnYPkG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 모델 훈련\n",
        "num_epochs = 5\n",
        "for epoch in range(num_epochs):\n",
        "    train_loss = train(model, train_dataloader, optimizer, criterion_classification, criterion_regression, device)\n",
        "    val_loss, val_predictions, val_scores, _, _ = evaluate(model, val_dataloader, criterion_classification, criterion_regression, device)\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
        "    print(f\"Train Loss: {train_loss:.4f}\")\n",
        "    print(f\"Validation Loss: {val_loss:.4f}\")\n",
        "\n",
        "# 모델 평가\n",
        "test_loss, test_predictions, test_scores, test_labels, test_review_scores = evaluate(model, test_dataloader, criterion_classification, criterion_regression, device)\n",
        "accuracy, mae = calculate_metrics(test_predictions, test_scores, test_labels, test_review_scores)\n",
        "print(f\"Test Loss: {test_loss:.4f}\")\n",
        "print(f\"Test Accuracy (Polarity): {accuracy:.4f}\")\n",
        "print(f\"Test MAE (Review Score): {mae:.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R3C1Tx3xVhHg",
        "outputId": "dacab26d-0b1a-4f72-b940-b217140b51d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4113/4113 [20:09<00:00,  3.40it/s]\n",
            "100%|██████████| 1029/1029 [01:50<00:00,  9.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "Train Loss: 0.9272\n",
            "Validation Loss: 0.8704\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4113/4113 [20:08<00:00,  3.40it/s]\n",
            "100%|██████████| 1029/1029 [01:50<00:00,  9.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/5\n",
            "Train Loss: 0.8626\n",
            "Validation Loss: 0.8607\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4113/4113 [20:10<00:00,  3.40it/s]\n",
            "100%|██████████| 1029/1029 [01:51<00:00,  9.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/5\n",
            "Train Loss: 0.8338\n",
            "Validation Loss: 0.8579\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4113/4113 [20:10<00:00,  3.40it/s]\n",
            "100%|██████████| 1029/1029 [01:51<00:00,  9.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/5\n",
            "Train Loss: 0.8042\n",
            "Validation Loss: 0.8493\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4113/4113 [20:10<00:00,  3.40it/s]\n",
            "100%|██████████| 1029/1029 [01:50<00:00,  9.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/5\n",
            "Train Loss: 0.7734\n",
            "Validation Loss: 0.8925\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 697/697 [01:15<00:00,  9.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.9385\n",
            "Test Accuracy (Polarity): 0.6710\n",
            "Test MAE (Review Score): 24.1453\n",
            "Text: [CLS] 좋은 [UNK] [UNK] [UNK] [UNK] [UNK] 되어 [UNK] [UNK]. [UNK] 처럼 [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
            "Predicted Polarity: 1, Actual Polarity: 1\n",
            "Predicted Score: 10.25, Actual Score: 100.00\n",
            "Text: [CLS] [UNK] [UNK] [UNK] [UNK] [UNK]. [UNK] [UNK] 보니 [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]. [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] 중 [UNK] [UNK] 합니다. [UNK] [UNK] 잘 [UNK] 좀 [UNK] 것 [UNK]. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
            "Predicted Polarity: 0, Actual Polarity: 0\n",
            "Predicted Score: 12.83, Actual Score: 100.00\n",
            "Text: [CLS] [UNK] [UNK] [UNK]. [UNK] [UNK] [UNK] [UNK] 되어 [UNK] [UNK] [UNK] 알 수 [UNK] [UNK] [UNK] [UNK] 수 [UNK] 좋은 것 [UNK]. [UNK] 제 [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
            "Predicted Polarity: 1, Actual Polarity: 0\n",
            "Predicted Score: 10.40, Actual Score: 100.00\n",
            "Text: [CLS] 다른 [UNK] [UNK] [UNK] [UNK]. [UNK] [UNK] [UNK]. [UNK] [UNK] 별로 [UNK] [UNK]. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
            "Predicted Polarity: -1, Actual Polarity: 0\n",
            "Predicted Score: 7.89, Actual Score: 100.00\n",
            "Text: [CLS] [UNK] [UNK] [UNK] [UNK]. [UNK] [UNK] 처음 [UNK] [UNK] [UNK] 더 [UNK] [UNK] 것 [UNK]. [UNK] [UNK] [UNK] [UNK]. [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]. [UNK] [UNK] [UNK] 더 좋은 것 [UNK]. 다 [UNK] [UNK] [UNK] [UNK] [UNK] 합니다. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
            "Predicted Polarity: 1, Actual Polarity: -1\n",
            "Predicted Score: 8.17, Actual Score: 80.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# 모델을 저장할 경로 지정\n",
        "MODEL_PATH = \"multi_task_model.pth\"\n",
        "\n",
        "# 모델의 state_dict 저장\n",
        "torch.save(model.state_dict(), MODEL_PATH)\n",
        "print(f\"Model saved to {MODEL_PATH}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DY6jmOBq_XPl",
        "outputId": "c3a1bf51-4246-4c36-ab8e-8f0af41d6b24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to multi_task_model2.pth\n"
          ]
        }
      ]
    }
  ]
}